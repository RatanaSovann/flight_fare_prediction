{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d2d79d-8fa9-4f24-8614-46d22f79e807",
   "metadata": {},
   "source": [
    "# 0. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c60240-71d7-488e-9dc0-27c027c048f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "from datetime import timedelta\n",
    "import isodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040d4c0-20bf-47f7-9a43-3d26768019dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'jupyterlab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7cc093-4280-4bf4-92c5-daa5cc280b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary tools for enhanced EDA\n",
    "!pip install summarytools\n",
    "from summarytools import dfSummary\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a960970-ef2f-4202-81a2-efe61d6b87b3",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e62da66-55d8-4967-9f12-b3e0c8cc63a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/OneDrive - UTS/Sem 4 (Spring 2024)/Advanced ML Applications/Assignment 3/adv_mla_at3/data/raw/df_airport.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793f95a-4eff-47f7-b689-6b289edda4a8",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac684e-60d5-42c4-b17c-12d10fbe3b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1eba2-a084-41b6-aed2-a94d7ba827ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381edf99-5bbb-477b-8a19-818c9c2e560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f50e70-00ae-4cce-82bf-dbd98c314459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef793506-c8ba-4c7b-98e0-0f080582ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values for desitination airport\n",
    "unique_airports = df['destinationAirport'].unique()\n",
    "print(unique_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57075283-293e-453c-8849-c944d055e320",
   "metadata": {},
   "source": [
    "**At a quick glance here are the observations made:**\n",
    "\n",
    "dimenstion:  9,467,508 x 23\n",
    "1. There are 4 starting airport (SFO, ORD, PHL, OAK) since I am working on this subset \n",
    "2. There are 16 destination airports. \n",
    "3. Most of the tickets are not Basic Economy (96.6%)\n",
    "4. Almost all the tickets are non refundable.\n",
    "5. The median total fare is about 408.6 dollars with the highest being at 8260 dollars. \n",
    "6. Median distance travelled is about 1784.0 miles with about 7% missing data.\n",
    "7. If there are transits, the segments are broken down with || for some of the features stating Departure and Arrival Airport, Airline name, airline model, duration, distance and cabin code.\n",
    "8. Data quality: there are 6,311,672 duplicate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c495a5-be11-4ec0-bb7f-5c6dc0d9d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86939aac-b07d-45bd-b541-d8bc81610c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert it to datetime \n",
    "df['searchDate'] = pd.to_datetime(df['searchDate'], errors='coerce')\n",
    "\n",
    "# Find the minimum and maximum dates\n",
    "min_date = df['searchDate'].min()\n",
    "max_date = df['searchDate'].max()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Minimum date: {min_date}\")\n",
    "print(f\"Maximum date: {max_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac76fcd-132c-4c07-b0c2-7b2b4870aedf",
   "metadata": {},
   "source": [
    "After converting the searchDate from object to Datetime, it is seen that the minimum date for searching a flight is on 16/4/2022 and the maximum date is 19/5/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf2be2-5196-4262-a296-fba01932a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert it to datetime \n",
    "df['flightDate'] = pd.to_datetime(df['flightDate'], errors='coerce')\n",
    "\n",
    "# Find the minimum and maximum dates\n",
    "min_date = df['flightDate'].min()\n",
    "max_date = df['flightDate'].max()\n",
    "\n",
    "# Display the results\n",
    "print(f\"Minimum date: {min_date}\")\n",
    "print(f\"Maximum date: {max_date}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc078ccd-c8b2-4fbc-8423-6ad758f047c4",
   "metadata": {},
   "source": [
    "After converting the flightDate from object to Datetime, it is seen that the minimum date for searching a flight is on 17/4/2022 and the maximum date is 17/7/2022. It means that some customers looked for flight on the next day from 16/4/2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46adc04-f2d0-48f0-8f5f-3841133a15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e45fb-7703-4762-9ade-c622d6e2160d",
   "metadata": {},
   "source": [
    "The total duration is in ISO 8601 format and it will be converted to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134bbec-d873-431f-97cf-b86da485f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep['travelDurationHours'] = df_prep['travelDuration'].apply(\n",
    "    lambda x: isodate.parse_duration(x).total_seconds() / 3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f96114d-3ae7-47ee-ae41-efd5ce13d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf7571-f9f7-4be4-b871-bf3351803532",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df_prep['travelDurationHours'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9b7b5-b023-467a-a751-bb6732887b6e",
   "metadata": {},
   "source": [
    "Based on this new feature, we can see that the median value for the flight duration is about 7.5 hours, minimum value is less than an hour and max is about 39.5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e709bc-7b48-44ad-ab82-5c78b5f34b22",
   "metadata": {},
   "source": [
    "### duplicate handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08955b71-b355-48e2-94ee-d1dfdc36c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of duplicate rows\n",
    "total_duplicates = df_prep.duplicated().sum()\n",
    "\n",
    "# Display the total count\n",
    "print(f\"Total number of duplicate rows: {total_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959670f-f312-42d0-963b-89cd604c0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's verify if all the columns match in some of the duplicates\n",
    "\n",
    "# Find all duplicate rows (including the first occurrence)\n",
    "duplicates = df_prep[df_prep.duplicated(keep=False)]\n",
    "\n",
    "# Sort the duplicates to group identical rows together\n",
    "grouped_duplicates = duplicates.sort_values(list(df_prep.columns))\n",
    "\n",
    "# Display the grouped duplicate observations\n",
    "grouped_duplicates.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd5f496-b156-4d5c-a00e-2dc7bc00e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_duplicates.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5580c4-c667-4421-9ca4-9c58de481ac3",
   "metadata": {},
   "source": [
    "Therefore we can conclude that there are actually duplicate observations and it's a significant number. 6,311,672/9,467,508 are duplicates which is 2/3 of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3ccbe-0f24-42fe-a63f-39d19e3025f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates\n",
    "df_prep = df_prep.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b344442-5f9f-4a05-9e12-3f5bf5b9c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of duplicate rows\n",
    "total_duplicates = df_prep.duplicated().sum()\n",
    "\n",
    "# Display the total count\n",
    "print(f\"Total number of duplicate rows: {total_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff0159-a5d3-477b-b508-84dbb2756c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89a3425-ff63-415d-a778-4b3983eb917b",
   "metadata": {},
   "source": [
    "It can be seen that the dataframe is now 1/3 of the initial size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecaf212-b518-4fbd-a246-1a737fd445ac",
   "metadata": {},
   "source": [
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df041c16-d47b-4f3d-9bb4-2743c6ef4011",
   "metadata": {},
   "source": [
    "##### Let's look at the distribution of the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfd9f28-70bc-4692-a971-941882f01af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    df_prep, \n",
    "    x='totalFare', \n",
    "    nbins=100,  \n",
    "    title='Distribution of Total Fare',\n",
    "    labels={'totalFare': 'Total Fare'},\n",
    "    width=800, \n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Limit the x-axis range to focus on the bulk of the data\n",
    "fig.update_layout(xaxis=dict(range=[0, 1000]))  \n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d236519-0fea-4fe0-bf2e-b0e89fa3cbd9",
   "metadata": {},
   "source": [
    "From the range and spread above, we can see that the totalFare values mainly fall bewteen 0 and 1000 dollars. The histogram is slighly right skewed and indicating that most fares are concentrated between 200 and 600. As fare amount increases, the frequency decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957cb7b9-093d-4b09-bbf3-13360347e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the box plot \n",
    "sns.boxplot(y=df_prep['totalFare'])\n",
    "plt.title('Box Plot of Total Fare')\n",
    "plt.ylabel('Total Fare')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc92c3-8118-446a-8f58-902e06eec3ab",
   "metadata": {},
   "source": [
    "From the box plot, we can see that the median fare is at the lower end (408). There are several datapoints which are beyond the upper whisker that go beyond 2000 dollars with some reaching as high as 8000 dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e054f70-02df-4386-8c69-7be48af9fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df_prep['totalFare'].quantile(0.25)\n",
    "Q3 = df_prep['totalFare'].quantile(0.75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the upper and lower bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = df_prep[(df_prep['totalFare'] < lower_bound) | (df_prep['totalFare'] > upper_bound)]\n",
    "\n",
    "# Count the number of outliers\n",
    "outlier_count = outliers.shape[0]\n",
    "\n",
    "# Display the result\n",
    "print(f\"Number of outliers in totalFare: {outlier_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd17fc-93a2-4212-829e-278788f17d2e",
   "metadata": {},
   "source": [
    "We can see that there are about 42,850 rows which are outliers (1.35% of data). Since my objective is to predict typical fares, I will remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753f99f-ce49-4e96-a264-be1e8aa2a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE OUTLIERS\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = df_prep['totalFare'].quantile(0.25)\n",
    "Q3 = df_prep['totalFare'].quantile(0.75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the upper and lower bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers from the DataFrame\n",
    "df_prep = df_prep[(df_prep['totalFare'] >= lower_bound) & (df_prep['totalFare'] <= upper_bound)]\n",
    "\n",
    "# Verify the new size of the DataFrame\n",
    "print(f\"Number of rows after removing outliers: {df_prep.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159779df-332f-40b0-98c8-813eddb37288",
   "metadata": {},
   "source": [
    "##### Let's look at the frequency of starting and destination airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10fc161-b993-48bc-be44-0cd7a5d0ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Count occurrences of each starting airport\n",
    "airport_counts = df_prep['startingAirport'].value_counts().reset_index()\n",
    "airport_counts.columns = ['startingAirport', 'Count']\n",
    "\n",
    "# Create the bar chart \n",
    "fig = px.bar(\n",
    "    airport_counts,\n",
    "    x='startingAirport',\n",
    "    y='Count',\n",
    "    title='Count of Flights by Starting Airport',\n",
    "    labels={'startingAirport': 'Starting Airport', 'Count': 'Number of Flights'},\n",
    "    width=600,  \n",
    "    height=500  \n",
    ")\n",
    "\n",
    "fig.update_traces(width=0.5)  \n",
    "\n",
    "# Plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f0dab-6c9b-41aa-8b53-1a4a2776d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each destination airport\n",
    "airport_counts = df_prep['destinationAirport'].value_counts().reset_index()\n",
    "airport_counts.columns = ['destinationAirport', 'Count']\n",
    "\n",
    "# Create the bar chart \n",
    "fig = px.bar(\n",
    "    airport_counts,\n",
    "    x='destinationAirport',\n",
    "    y='Count',\n",
    "    title='Count of Flights by Destination Airport',\n",
    "    labels={'destinationAirport': 'Destination Airport', 'Count': 'Number of Flights'},\n",
    "    width=600,  \n",
    "    height=500  \n",
    ")\n",
    "\n",
    "\n",
    "fig.update_traces(width=0.5)  \n",
    "\n",
    "# Plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb66eef-32eb-4cf9-9d1b-f31c114c5497",
   "metadata": {},
   "source": [
    "We can see that the highest frequency of flights took off from SFO and the least from OAK. The highest frequency destination airport was LGA and the least was OAK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe04ef1-056a-4c38-bc4b-3487b39f7776",
   "metadata": {},
   "source": [
    "##### Distribution of total travel distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c1fdb-76bd-4da7-8553-224fc3b37fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Set plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Step 2: Create a histogram using Seaborn\n",
    "sns.histplot(df_prep['totalTravelDistance'], bins=50, kde=True)\n",
    "\n",
    "# Step 3: Add title and labels\n",
    "plt.title('Distribution of Total Travel Distance')\n",
    "plt.xlabel('Total Travel Distance')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Step 4: Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857a295-7d1c-4222-8948-67a1128481e2",
   "metadata": {},
   "source": [
    "The distribution of totalTravelDistance shows a multi-modal pattern with several peaks at different intervals (e.g., around 500, 1000, 2500). Based on mulitple peaks, we can deduce that there are several distinct groups of travel distances, suggesting flights of varying lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b200d5d-8f46-4415-9797-cef164c884b7",
   "metadata": {},
   "source": [
    "##### Look at the first segment distribution of flights with more than one layovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4561f-f44c-4639-99ec-a957efb8e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first segment (before the first '|') from 'segmentsCabinCode'\n",
    "df_prep['firstSegmentCabinCode'] = df_prep['segmentsCabinCode'].str.split('|').str[0]\n",
    "\n",
    "# Count the frequency of the first segments\n",
    "first_segment_counts = df_prep['firstSegmentCabinCode'].value_counts()\n",
    "\n",
    "# Display the frequency\n",
    "print(first_segment_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a429f5-db20-4191-96a1-8625213527bf",
   "metadata": {},
   "source": [
    "We can see that majority of the observations have coach as the cabin code for the first segment of the flight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49a156-78ea-431b-ae83-8aeef1464aeb",
   "metadata": {},
   "source": [
    "##### Look at the first segment distribution of airlines with more than one layovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2fdfa-2473-4455-a3fe-a7a4c57ddd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the first airline name (before the first '|') from 'segmentsAirlineName'\n",
    "df_prep['firstSegmentAirline'] = df_prep['segmentsAirlineName'].str.split('|').str[0]\n",
    "\n",
    "# Count the frequency of the first airline names\n",
    "first_airline_counts = df_prep['firstSegmentAirline'].value_counts()\n",
    "\n",
    "# Display the frequency\n",
    "print(first_airline_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d3ffe-0146-4f2d-953b-0a35677c42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a histogram with KDE overlay\n",
    "sns.histplot(df_prep['travelDurationHours'], bins=30, kde=True)\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of Travel Duration in Hours')\n",
    "plt.xlabel('Travel Duration (Hours)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c751dd-48e6-4ee8-8484-5a44628120c8",
   "metadata": {},
   "source": [
    "From the chart above, we can see that majority of the flights have a shorter travel duration (2-10 hours) with  a decreasing number of longer flights. There are some flights that extend up to 40 hours but very rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb9fcb-1f19-4b7e-ae9a-a9b8764e9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to interim folder\n",
    "file_path = 'E:/OneDrive - UTS/Sem 4 (Spring 2024)/Advanced ML Applications/Assignment 3/adv_mla_at3/data/interim/df_airport_farhan_faiyaz.csv'\n",
    "df_prep.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78391152-19c6-4cd1-bf6a-72802863de23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
