{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fa81b8-de7c-4ab4-99ac-28201b501a0e",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e26e83-30ac-4149-accd-87b992e4a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package Versions:\n",
      "----------------------------------------\n",
      "Pandas................... v2.2.2\n",
      "Seaborn.................. v0.13.2\n",
      "XGBoost.................. v2.1.1\n",
      "Optuna................... v4.0.0\n",
      "Scikit-learn............. v1.5.1\n",
      "NumPy.................... v1.26.4\n",
      "Matplotlib............... v3.9.2\n",
      "Category Encoders........ v2.6.4\n",
      "Joblib................... v1.4.2\n",
      "CatBoost................. v1.2.7\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import sklearn\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import joblib\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "#  version info dictionary\n",
    "versions = {\n",
    "    \"Pandas\": pd.__version__,\n",
    "    \"Seaborn\": sns.__version__,\n",
    "    \"XGBoost\": xgb.__version__,\n",
    "    \"Optuna\": optuna.__version__,\n",
    "    \"Scikit-learn\": sklearn.__version__,\n",
    "    \"NumPy\": np.__version__,\n",
    "    \"Matplotlib\": plt.__version__,\n",
    "    \"Category Encoders\": ce.__version__,\n",
    "    \"Joblib\": joblib.__version__,\n",
    "    \"CatBoost\": cb.__version__,\n",
    "}\n",
    "\n",
    "# Print versions \n",
    "print(\"Package Versions:\")\n",
    "print(\"-\" * 40)\n",
    "for package, version in versions.items():\n",
    "    print(f\"{package:.<25} v{version}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3157863d-f087-4694-8e18-247817cdc885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sadmansakib/Downloads/AdvanceML/adv_mla_at3/notebooks'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71e7a2c-e12a-4f2f-96ec-b8443befd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('../data/processed/train_data.csv')\n",
    "val_data = pd.read_csv('../data/processed/val_data.csv')\n",
    "test_data = pd.read_csv('../data/processed/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154e6633-4948-4f2e-9395-606e195870c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 295736 entries, 0 to 295735\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   startingAirport      295736 non-null  object \n",
      " 1   destinationAirport   295736 non-null  object \n",
      " 2   travelDuration       295736 non-null  float64\n",
      " 3   isBasicEconomy       295736 non-null  int64  \n",
      " 4   isRefundable         295736 non-null  bool   \n",
      " 5   isNonStop            295736 non-null  bool   \n",
      " 6   totalFare            295736 non-null  float64\n",
      " 7   totalTravelDistance  295736 non-null  float64\n",
      " 8   month                295736 non-null  int64  \n",
      " 9   day                  295736 non-null  int64  \n",
      " 10  day_of_week          295736 non-null  int64  \n",
      " 11  week_of_year         295736 non-null  int64  \n",
      " 12  date_diff            295736 non-null  int64  \n",
      " 13  hour                 295736 non-null  int64  \n",
      " 14  minute               295736 non-null  int64  \n",
      " 15  cabin_Leg1           295736 non-null  object \n",
      " 16  cabin_Leg2           295736 non-null  object \n",
      " 17  cabin_Leg3           295736 non-null  object \n",
      " 18  cabin_Leg4           295736 non-null  object \n",
      "dtypes: bool(2), float64(3), int64(8), object(6)\n",
      "memory usage: 38.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba7f9d4d-78b1-40d8-9df9-ccb6edc72f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to integers for all datasets\n",
    "for dataset in [train_data, val_data, test_data]:\n",
    "    dataset['isRefundable'] = dataset['isRefundable'].astype(int)\n",
    "    dataset['isNonStop'] = dataset['isNonStop'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f5fbbc2-9475-465f-9470-e5d04f5c7619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 295736 entries, 0 to 295735\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   startingAirport      295736 non-null  object \n",
      " 1   destinationAirport   295736 non-null  object \n",
      " 2   travelDuration       295736 non-null  float64\n",
      " 3   isBasicEconomy       295736 non-null  int64  \n",
      " 4   isRefundable         295736 non-null  int64  \n",
      " 5   isNonStop            295736 non-null  int64  \n",
      " 6   totalFare            295736 non-null  float64\n",
      " 7   totalTravelDistance  295736 non-null  float64\n",
      " 8   month                295736 non-null  int64  \n",
      " 9   day                  295736 non-null  int64  \n",
      " 10  day_of_week          295736 non-null  int64  \n",
      " 11  week_of_year         295736 non-null  int64  \n",
      " 12  date_diff            295736 non-null  int64  \n",
      " 13  hour                 295736 non-null  int64  \n",
      " 14  minute               295736 non-null  int64  \n",
      " 15  cabin_Leg1           295736 non-null  object \n",
      " 16  cabin_Leg2           295736 non-null  object \n",
      " 17  cabin_Leg3           295736 non-null  object \n",
      " 18  cabin_Leg4           295736 non-null  object \n",
      "dtypes: float64(3), int64(10), object(6)\n",
      "memory usage: 42.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c0092-12f5-47e5-b0a5-1ba8948f646c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06d44db4-7e96-4b41-aab6-9be1404dc132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target_column = 'totalFare'\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = [\n",
    "    'startingAirport', 'destinationAirport',\n",
    "    'cabin_Leg1', 'cabin_Leg2', 'cabin_Leg3', 'cabin_Leg4'\n",
    "]\n",
    "\n",
    "numerical_features = [\n",
    "    'travelDuration', 'isBasicEconomy', 'isRefundable', 'isNonStop',\n",
    "    'totalTravelDistance', 'month', 'day', 'day_of_week', 'week_of_year',\n",
    "    'date_diff', 'hour', 'minute'\n",
    "]\n",
    "\n",
    "# Combine features\n",
    "feature_columns = numerical_features + categorical_features\n",
    "\n",
    "# Prepare training data\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data[target_column]\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = val_data[feature_columns]\n",
    "y_val = val_data[target_column]\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data[target_column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6ea39-6b8e-4065-a00b-5bf5ff6b5cf4",
   "metadata": {},
   "source": [
    "### 1.Liner Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0716c973-b4ae-473a-a75b-4e703b64c110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "RMSE: $166.75\n",
      "MAE: $111.97\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $172.68\n",
      "MAE: $113.01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Create preprocessing pipelines for both numeric and categorical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessor and model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on train and validation sets\n",
    "train_predictions = model.predict(X_train)\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Calculate and display metrics\n",
    "def display_metrics(y_true, y_pred, dataset_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"RMSE: ${rmse:.2f}\")\n",
    "    print(f\"MAE: ${mae:.2f}\")\n",
    "\n",
    "# Print metrics for both sets\n",
    "display_metrics(y_train, train_predictions, \"Training\")\n",
    "display_metrics(y_val, val_predictions, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc442ee-e573-4df8-a55d-3828767170e0",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8a645f7-cabb-4174-83bb-5e43339e0976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models with Grid Search CV...\n",
      "\n",
      "Ridge Best Parameters:\n",
      "{'regressor__alpha': 0.1, 'regressor__solver': 'auto'}\n",
      "Ridge Best Score (RMSE): $166.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.691e+09, tolerance: 1.180e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+09, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+09, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.676e+09, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.241e+07, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+09, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+09, tolerance: 1.180e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+09, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.268e+06, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.228e+06, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+09, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+09, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+09, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.695e+09, tolerance: 1.478e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Best Parameters:\n",
      "{'regressor__alpha': 0.01, 'regressor__selection': 'cyclic'}\n",
      "Lasso Best Score (RMSE): $167.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.928e+07, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.081e+07, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+07, tolerance: 1.180e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.987e+07, tolerance: 1.179e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.420e+07, tolerance: 1.188e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.023e+07, tolerance: 1.478e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ElasticNet Best Parameters:\n",
      "{'regressor__alpha': 0.01, 'regressor__l1_ratio': 0.9}\n",
      "ElasticNet Best Score (RMSE): $168.17\n",
      "\n",
      "Evaluating final models...\n",
      "\n",
      "Ridge Final Metrics:\n",
      "Training Metrics:\n",
      "RMSE: $166.75\n",
      "MAE: $111.98\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $172.68\n",
      "MAE: $113.01\n",
      "\n",
      "Lasso Final Metrics:\n",
      "Training Metrics:\n",
      "RMSE: $166.87\n",
      "MAE: $111.98\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $172.90\n",
      "MAE: $113.06\n",
      "\n",
      "ElasticNet Final Metrics:\n",
      "Training Metrics:\n",
      "RMSE: $168.09\n",
      "MAE: $112.37\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $174.26\n",
      "MAE: $113.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create pipelines for different models\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Lasso())\n",
    "])\n",
    "\n",
    "elastic_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', ElasticNet())\n",
    "])\n",
    "\n",
    "# Define parameter grids for each model\n",
    "ridge_params = {\n",
    "    'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'regressor__solver': ['auto', 'svd', 'cholesky', 'lsqr']\n",
    "}\n",
    "\n",
    "lasso_params = {\n",
    "    'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'regressor__selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "elastic_params = {\n",
    "    'regressor__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'regressor__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "# Perform Grid Search for each model\n",
    "def train_and_evaluate_model(pipeline, params, model_name):\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        params,\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\\n{model_name} Best Parameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"{model_name} Best Score (RMSE): ${-grid_search.best_score_:.2f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Train and evaluate all models\n",
    "print(\"Training models with Grid Search CV...\")\n",
    "ridge_model = train_and_evaluate_model(ridge_pipeline, ridge_params, \"Ridge\")\n",
    "lasso_model = train_and_evaluate_model(lasso_pipeline, lasso_params, \"Lasso\")\n",
    "elastic_model = train_and_evaluate_model(elastic_pipeline, elastic_params, \"ElasticNet\")\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    val_mae = mean_absolute_error(y_val, val_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Final Metrics:\")\n",
    "    print(\"Training Metrics:\")\n",
    "    print(f\"RMSE: ${train_rmse:.2f}\")\n",
    "    print(f\"MAE: ${train_mae:.2f}\")\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    print(f\"RMSE: ${val_rmse:.2f}\")\n",
    "    print(f\"MAE: ${val_mae:.2f}\")\n",
    "\n",
    "# Evaluate all models\n",
    "print(\"\\nEvaluating final models...\")\n",
    "evaluate_model(ridge_model, X_train, y_train, X_val, y_val, \"Ridge\")\n",
    "evaluate_model(lasso_model, X_train, y_train, X_val, y_val, \"Lasso\")\n",
    "evaluate_model(elastic_model, X_train, y_train, X_val, y_val, \"ElasticNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b36d6-801f-4324-8aea-8148cef11e24",
   "metadata": {},
   "source": [
    "#### performing the best one(RIDGE) in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fb91c95-6c77-4054-bc12-8ab7af92288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "RMSE: $170.04\n",
      "MAE: $113.84\n",
      "\n",
      "Prediction Interval (95% confidence):\n",
      "±$326.82\n",
      "\n",
      "Sample Predictions vs Actual Values:\n",
      "\n",
      "Actual Price vs Predicted Price:\n",
      "Actual: $438.70, Predicted: $529.87, Difference: $91.17\n",
      "Actual: $294.60, Predicted: $423.39, Difference: $128.79\n",
      "Actual: $554.01, Predicted: $369.77, Difference: $184.24\n",
      "Actual: $465.60, Predicted: $454.93, Difference: $10.67\n",
      "Actual: $576.60, Predicted: $488.60, Difference: $88.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = ridge_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"RMSE: ${test_rmse:.2f}\")\n",
    "print(f\"MAE: ${test_mae:.2f}\")\n",
    "\n",
    "# Optional: Calculate and display prediction intervals (assuming normal distribution)\n",
    "residuals = y_train - ridge_model.predict(X_train)\n",
    "residual_std = np.std(residuals)\n",
    "\n",
    "confidence_interval = 1.96 * residual_std  # 95% confidence interval\n",
    "print(f\"\\nPrediction Interval (95% confidence):\")\n",
    "print(f\"±${confidence_interval:.2f}\")\n",
    "\n",
    "# Optional: Display some example predictions vs actual values\n",
    "print(\"\\nSample Predictions vs Actual Values:\")\n",
    "sample_size = min(5, len(y_test))\n",
    "sample_indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "\n",
    "print(\"\\nActual Price vs Predicted Price:\")\n",
    "for idx in sample_indices:\n",
    "    print(f\"Actual: ${y_test.iloc[idx]:.2f}, Predicted: ${test_predictions[idx]:.2f}, \" \n",
    "          f\"Difference: ${abs(y_test.iloc[idx] - test_predictions[idx]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27e823-057b-4328-adcc-b61bb18bc516",
   "metadata": {},
   "source": [
    "### 2.Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddf7399e-3aa2-4c29-a9de-cd25d978f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "RMSE: $11.16\n",
      "MAE: $0.49\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $127.76\n",
      "MAE: $66.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Create preprocessing pipelines with unique names\n",
    "dt_numeric_transformer = Pipeline(steps=[\n",
    "    ('dt_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "dt_categorical_transformer = Pipeline(steps=[\n",
    "    ('dt_onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "dt_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('dt_num', dt_numeric_transformer, numerical_features),\n",
    "        ('dt_cat', dt_categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with Decision Tree\n",
    "dt_model = Pipeline(steps=[\n",
    "    ('dt_preprocessor', dt_preprocessor),\n",
    "    ('dt_regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_train_predictions = dt_model.predict(X_train)\n",
    "dt_val_predictions = dt_model.predict(X_val)\n",
    "\n",
    "# Calculate and display metrics\n",
    "def display_dt_metrics(y_true, y_pred, dataset_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"RMSE: ${rmse:.2f}\")\n",
    "    print(f\"MAE: ${mae:.2f}\")\n",
    "\n",
    "# Print metrics for both sets\n",
    "display_dt_metrics(y_train, dt_train_predictions, \"Training\")\n",
    "display_dt_metrics(y_val, dt_val_predictions, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac77ce4e-61fe-42e0-b3c6-0709dcd435c8",
   "metadata": {},
   "source": [
    "**The model is clearly overfitted. In the training set, it performed very well with high accuracy, but in the unseen dataset (validation set), it's not performing well at all, showing poor generalization ability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d58a4b3-e201-4418-ba05-6ab632239017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree model with Grid Search CV...\n",
      "\n",
      "Best Parameters:\n",
      "{'dt_regressor__max_depth': None, 'dt_regressor__max_features': None, 'dt_regressor__min_samples_leaf': 4, 'dt_regressor__min_samples_split': 10}\n",
      "Best Cross-Validation RMSE: $115.21\n",
      "\n",
      "Final Metrics with Best Model:\n",
      "\n",
      "Training Metrics:\n",
      "RMSE: $68.70\n",
      "MAE: $39.84\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $117.08\n",
      "MAE: $66.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create pipeline with Decision Tree\n",
    "dt_pipeline_tuning = Pipeline([\n",
    "    ('dt_preprocessor', dt_preprocessor),\n",
    "    ('dt_regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "dt_param_grid = {\n",
    "    'dt_regressor__max_depth': [5, 10, 15, 20, None],\n",
    "    'dt_regressor__min_samples_split': [2, 5, 10],\n",
    "    'dt_regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'dt_regressor__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "dt_grid_search = GridSearchCV(\n",
    "    dt_pipeline_tuning,\n",
    "    dt_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Decision Tree model with Grid Search CV...\")\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(dt_grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation RMSE: ${-dt_grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Get best model\n",
    "dt_best_model = dt_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with best model\n",
    "dt_best_train_predictions = dt_best_model.predict(X_train)\n",
    "dt_best_val_predictions = dt_best_model.predict(X_val)\n",
    "\n",
    "# Print metrics for both sets\n",
    "print(\"\\nFinal Metrics with Best Model:\")\n",
    "display_dt_metrics(y_train, dt_best_train_predictions, \"Training\")\n",
    "display_dt_metrics(y_val, dt_best_val_predictions, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f348486-cb2a-45e3-9680-f96a018f4d20",
   "metadata": {},
   "source": [
    "**The model shows less overfitting than before, as the gap between training and validation metrics has decreased.still there are room for improvment.still model is overfitted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "496618e3-d9f0-47f7-a5c2-e9e8594bf447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Test Set Metrics:\n",
      "RMSE: $110.75\n",
      "MAE: $66.28\n",
      "\n",
      "Sample Predictions vs Actual Values:\n",
      "\n",
      "Actual Price vs Predicted Price:\n",
      "Actual: $351.60, Predicted: $351.03, Difference: $0.57\n",
      "Actual: $176.60, Predicted: $211.79, Difference: $35.19\n",
      "Actual: $359.10, Predicted: $371.49, Difference: $12.39\n",
      "Actual: $658.10, Predicted: $621.93, Difference: $36.17\n",
      "Actual: $200.60, Predicted: $237.45, Difference: $36.85\n",
      "\n",
      "Top Numerical Features by Importance:\n",
      "                feature  importance\n",
      "4   totalTravelDistance    0.339155\n",
      "0        travelDuration    0.077766\n",
      "9             date_diff    0.049508\n",
      "7           day_of_week    0.037546\n",
      "1        isBasicEconomy    0.032346\n",
      "10                 hour    0.029176\n",
      "6                   day    0.029101\n",
      "8          week_of_year    0.028906\n",
      "11               minute    0.024061\n",
      "5                 month    0.003093\n",
      "3             isNonStop    0.000180\n",
      "2          isRefundable    0.000002\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "dt_test_predictions = dt_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "dt_test_rmse = np.sqrt(mean_squared_error(y_test, dt_test_predictions))\n",
    "dt_test_mae = mean_absolute_error(y_test, dt_test_predictions)\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nDecision Tree Test Set Metrics:\")\n",
    "print(f\"RMSE: ${dt_test_rmse:.2f}\")\n",
    "print(f\"MAE: ${dt_test_mae:.2f}\")\n",
    "\n",
    "# Optional: Show some example predictions\n",
    "print(\"\\nSample Predictions vs Actual Values:\")\n",
    "sample_size = min(5, len(y_test))\n",
    "sample_indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "\n",
    "print(\"\\nActual Price vs Predicted Price:\")\n",
    "for idx in sample_indices:\n",
    "    print(f\"Actual: ${y_test.iloc[idx]:.2f}, Predicted: ${dt_test_predictions[idx]:.2f}, \"\n",
    "          f\"Difference: ${abs(y_test.iloc[idx] - dt_test_predictions[idx]):.2f}\")\n",
    "\n",
    "# Simple feature importance for numerical features only\n",
    "dt_feature_importance = pd.DataFrame({\n",
    "    'feature': numerical_features,\n",
    "    'importance': dt_best_model.named_steps['dt_regressor'].feature_importances_[:len(numerical_features)]\n",
    "})\n",
    "dt_feature_importance = dt_feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop Numerical Features by Importance:\")\n",
    "print(dt_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8b68d-59c7-41c0-ba2a-e1a1cb92f1db",
   "metadata": {},
   "source": [
    "### 3.Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bca65d9e-9c5f-4bc8-84b5-e07331941ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Metrics:\n",
      "RMSE: $34.20\n",
      "MAE: $19.76\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $94.22\n",
      "MAE: $52.53\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Create preprocessing pipelines with unique names\n",
    "rf_numeric_transformer = Pipeline(steps=[\n",
    "    ('rf_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "rf_categorical_transformer = Pipeline(steps=[\n",
    "    ('rf_onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "rf_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('rf_num', rf_numeric_transformer, numerical_features),\n",
    "        ('rf_cat', rf_categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create pipeline with Random Forest\n",
    "rf_model = Pipeline(steps=[\n",
    "    ('rf_preprocessor', rf_preprocessor),\n",
    "    ('rf_regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_train_predictions = rf_model.predict(X_train)\n",
    "rf_val_predictions = rf_model.predict(X_val)\n",
    "\n",
    "# Calculate and display metrics\n",
    "def display_rf_metrics(y_true, y_pred, dataset_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"RMSE: ${rmse:.2f}\")\n",
    "    print(f\"MAE: ${mae:.2f}\")\n",
    "\n",
    "# Print metrics for both sets\n",
    "display_rf_metrics(y_train, rf_train_predictions, \"Training\")\n",
    "display_rf_metrics(y_val, rf_val_predictions, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad65dab5-eea0-42a0-b4e6-72257027af91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model with Grid Search CV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.11/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters:\n",
      "{'rf_regressor__max_depth': None, 'rf_regressor__max_features': 'sqrt', 'rf_regressor__min_samples_leaf': 1, 'rf_regressor__min_samples_split': 2, 'rf_regressor__n_estimators': 200}\n",
      "Best Cross-Validation RMSE: $93.78\n",
      "\n",
      "Final Metrics with Best Model:\n",
      "\n",
      "Training Metrics:\n",
      "RMSE: $34.85\n",
      "MAE: $20.76\n",
      "\n",
      "Validation Metrics:\n",
      "RMSE: $97.22\n",
      "MAE: $55.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create pipeline with Random Forest\n",
    "rf_pipeline_tuning = Pipeline([\n",
    "    ('rf_preprocessor', rf_preprocessor),\n",
    "    ('rf_regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_grid = {\n",
    "    'rf_regressor__n_estimators': [100, 200],\n",
    "    'rf_regressor__max_depth': [10, 20, None],\n",
    "    'rf_regressor__min_samples_split': [2, 5],\n",
    "    'rf_regressor__min_samples_leaf': [1, 2],\n",
    "    'rf_regressor__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "rf_grid_search = GridSearchCV(\n",
    "    rf_pipeline_tuning,\n",
    "    rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest model with Grid Search CV...\")\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(rf_grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation RMSE: ${-rf_grid_search.best_score_:.2f}\")\n",
    "\n",
    "# Get best model\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with best model\n",
    "rf_best_train_predictions = rf_best_model.predict(X_train)\n",
    "rf_best_val_predictions = rf_best_model.predict(X_val)\n",
    "\n",
    "# Print metrics for both sets\n",
    "print(\"\\nFinal Metrics with Best Model:\")\n",
    "display_rf_metrics(y_train, rf_best_train_predictions, \"Training\")\n",
    "display_rf_metrics(y_val, rf_best_val_predictions, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e9092-52d1-4afc-a24a-83b26a61aae4",
   "metadata": {},
   "source": [
    "**A better result was achieved in the unseen dataset, but there is room for improvement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6cb94f0d-33a3-4c3b-aa98-9d85b3aa2e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Test Set Metrics:\n",
      "RMSE: $91.79\n",
      "MAE: $55.84\n",
      "\n",
      "Sample Predictions vs Actual Values:\n",
      "\n",
      "Actual Price vs Predicted Price:\n",
      "Actual: $221.58, Predicted: $262.56, Difference: $40.98\n",
      "Actual: $483.60, Predicted: $484.91, Difference: $1.31\n",
      "Actual: $326.20, Predicted: $382.03, Difference: $55.83\n",
      "Actual: $296.20, Predicted: $358.29, Difference: $62.09\n",
      "Actual: $268.60, Predicted: $272.90, Difference: $4.30\n",
      "\n",
      "Top Numerical Features by Importance:\n",
      "                feature  importance\n",
      "4   totalTravelDistance    0.188719\n",
      "0        travelDuration    0.095137\n",
      "9             date_diff    0.064717\n",
      "11               minute    0.051243\n",
      "10                 hour    0.048961\n",
      "6                   day    0.042555\n",
      "7           day_of_week    0.042107\n",
      "8          week_of_year    0.035996\n",
      "1        isBasicEconomy    0.024900\n",
      "5                 month    0.013659\n",
      "3             isNonStop    0.007210\n",
      "2          isRefundable    0.000979\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "rf_test_predictions = rf_best_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, rf_test_predictions))\n",
    "rf_test_mae = mean_absolute_error(y_test, rf_test_predictions)\n",
    "\n",
    "# Display test metrics\n",
    "print(\"\\nRandom Forest Test Set Metrics:\")\n",
    "print(f\"RMSE: ${rf_test_rmse:.2f}\")\n",
    "print(f\"MAE: ${rf_test_mae:.2f}\")\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\nSample Predictions vs Actual Values:\")\n",
    "sample_size = min(5, len(y_test))\n",
    "sample_indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "\n",
    "print(\"\\nActual Price vs Predicted Price:\")\n",
    "for idx in sample_indices:\n",
    "    print(f\"Actual: ${y_test.iloc[idx]:.2f}, Predicted: ${rf_test_predictions[idx]:.2f}, \"\n",
    "          f\"Difference: ${abs(y_test.iloc[idx] - rf_test_predictions[idx]):.2f}\")\n",
    "\n",
    "# Simple feature importance for numerical features\n",
    "rf_feature_importance = pd.DataFrame({\n",
    "    'feature': numerical_features,\n",
    "    'importance': rf_best_model.named_steps['rf_regressor'].feature_importances_[:len(numerical_features)]\n",
    "})\n",
    "rf_feature_importance = rf_feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop Numerical Features by Importance:\")\n",
    "print(rf_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aad102-00e7-4333-9df4-d4c6ae450ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4afd222-1500-45d0-8d33-590c4137a999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6fcc55-a124-4078-8ef7-36b54c396a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ca920-c68c-40f3-b6ca-919feb692aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5132844a-8c92-4861-a58a-a19ef6277e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
